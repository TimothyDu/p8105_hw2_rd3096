p8105_hw2_rd3096
================

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

\#problem1

\##load the nyc transit data and clean names

``` r
nyc_subway=
  read_csv("./NYCSUB.csv",na=c("NA","",".")) %>% 
  janitor::clean_names()
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

\##clean the data as requested

``` r
nyc_subway_clean=nyc_subway %>% 
  select(
    line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(
    entry=
      case_match(
      entry,
      "YES"~TRUE,
      "NO"~ FALSE),
      entry=as.logical(entry)
    )
```

## a short paragraph describing the dataset

The NYC subway dataset contains 1,868 rows and 19 columns. It includes
variables such as line, which represents the subway line (e.g., “4
Avenue”), station_name for the subway station (e.g., “25th St”),
geographical coordinates (station_latitude and station_longitude), and
various subway routes from route1 to route11. Additionally, the dataset
has information on the type of entrance (entrance_type), whether vending
machines are available (vending), and whether the station is ADA
compliant (ada). For the cleaning process, I retained only the necessary
variables and transformed the entry variable, which originally contained
“YES” and “NO” as character values, into a logical format (TRUE/FALSE).
After cleaning, the dataset consists of 1,868 observations and retains
the 19 original columns. While the data is fairly tidy, further steps
may be needed to handle the route variables, which are currently spread
across multiple columns.

\##Answer the Questions: \*How many distinct stations are there? Note
that stations are identified both by name and by line (e.g. 125th St 8th
Avenue; 125st Broadway; 125st Lenox); the distinct function may be
useful here.

``` r
distinct_stations=
  nyc_subway_clean %>% 
  distinct(station_name,line) %>% 
  nrow()
```

1.  There are 465 number of distinct stations are stored in
    distinct_stations.

\*How many stations are ADA compliant?

``` r
ada_compliant_stations=
  nyc_subway_clean %>% 
  filter(ada==TRUE) %>% 
  nrow()
```

2.  There are 468 stations are ADA compliant.

\*What proportion of station entrances / exits without vending allow
entrance?

``` r
proportion_no_vending_allows_entry=
  nyc_subway_clean %>%
  filter(vending == "NO") %>%
  summarize(proportion = mean(entry))
```

3.  37.7% of station entrances / exits without vending allow entrance.

\##reformat the data to make route number and rount names distinct
variables

``` r
nyc_subway_routes_clean= 
  nyc_subway_clean %>%
  mutate(across(route1:route11,as.character)) %>% 
  pivot_longer(
    route1:route11, 
    names_to = "route_number", 
    values_to = "route_name" 
  )
```

\##number of distinct stations serve the A train

``` r
a_train_stations=
  nyc_subway_routes_clean %>%
  filter(route_name == "A") %>% 
  distinct(station_name, line) %>% 
  nrow()
```

There are 60 disctinct stations serve the A train.

\##number of distinct stations serve the A train that are complaint
train

``` r
# Find ADA-compliant stations that serve the A train
ada_compliant_a_train_stations=
  nyc_subway_routes_clean %>%
  filter(route_name == "A", ada == TRUE) %>%
  distinct(station_name, line) %>% 
  nrow()
```

Of the stations that serve the A train, 17 are ADA compliant

\#problem 2

``` r
library(readxl)
library(dplyr)
```

\##read the Mr. Trash Wheel excel file and clean the data

``` r
mr_trash_wheel=
  read_excel("./trashwheel.xlsx", sheet="Mr. Trash Wheel", skip=1) %>% janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls=as.integer(round(sports_balls))) %>%
  select(dumpster:homes_powered) %>% 
  mutate(year = as.character(year)) %>% 
mutate(trash_wheel = "Mr. Trash Wheel")
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

\##read the Professor Trash Wheel excel file and clean the data

``` r
professor_trash_wheel=
  read_excel("./trashwheel.xlsx", sheet="Professor Trash Wheel", skip=1) %>% janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  select(dumpster:homes_powered) %>% 
  mutate(year = as.character(year)) %>% 
mutate(trash_wheel = "Professor. Trash Wheel")
```

\##read the Professor Trash Wheel excel file and clean the data

``` r
gwynnda_trash_wheel=
  read_excel("./trashwheel.xlsx", sheet="Gwynnda Trash Wheel", skip=1) %>% janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  select(dumpster:homes_powered) %>% 
  mutate(year = as.character(year)) %>% 
mutate(trash_wheel = "Gwynnda. Trash Wheel")
```

## combine the datafiles using binding

``` r
combined_trash_wheel=
  bind_rows(
    mr_trash_wheel, 
    professor_trash_wheel, 
    gwynnda_trash_wheel) %>% 
  relocate(trash_wheel)
```

The number of observations in the combined datafile is 845.Key variables
in the dataset include `dumpster`, which identifies the dumpster used,
`weight_tons` for the weight of trash collected, and `cigarette_butts`
for the number of cigarette butts collected.

``` r
total_weight_professor= combined_trash_wheel %>%
  filter(trash_wheel == "Professor. Trash Wheel") %>%
  summarize(total_weight = sum(weight_tons, na.rm = TRUE)) %>%
  pull(total_weight)

total_cig_butts_gwynnda_june=
  combined_trash_wheel %>%
  filter(trash_wheel == "Gwynnda. Trash Wheel", month == "June", year == "2022") %>%
  summarize(total_cig_butts = sum(cigarette_butts, na.rm = TRUE)) %>%
  pull(total_cig_butts)
```

The total weight of trash collected by Professor Trash Wheel is 216.26,
the total number of cigarette butts collected by Gwynnda in June of 2022
is 18120.

\#Problem 3

import, clean and Tidy baker.csv

``` r
baker_clean=
  read_csv("./gbb/bakers.csv",na=c("NA","",".")) %>% 
  janitor::clean_names() %>% 
  separate(baker_name, into=c("baker","last_name"),sep = " ", extra = "merge") %>% 
  relocate(baker) %>% 
  arrange(baker)
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bake_clean=
  read_csv("./gbb/bakes.csv", na=c("N/A","","UNKNOWN","Unknown")) %>%
  janitor::clean_names() %>% 
  relocate(baker)
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
result_clean=
  read_csv("./gbb/results.csv",na=c("NA","","."),skip=2) %>% 
  janitor::clean_names() %>% 
  relocate(baker)
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(baker_clean)
```

    ## # A tibble: 6 × 6
    ##   baker   last_name  series baker_age baker_occupation   hometown               
    ##   <chr>   <chr>       <dbl>     <dbl> <chr>              <chr>                  
    ## 1 Ali     Imdad           4        25 Charity worker     Saltley, Birmingham    
    ## 2 Alice   Fevronia       10        28 Geography teacher  Essex                  
    ## 3 Alvin   Magallanes      6        37 Nurse              Bracknell, Berkshire   
    ## 4 Amelia  LeBruin        10        24 Fashion designer   Halifax                
    ## 5 Andrew  Smyth           7        25 Aerospace engineer Derby / Holywood, Coun…
    ## 6 Annetha Mills           1        30 Midwife            Essex

``` r
head(bake_clean)
```

    ## # A tibble: 6 × 5
    ##   baker     series episode signature_bake                           show_stopper
    ##   <chr>      <dbl>   <dbl> <chr>                                    <chr>       
    ## 1 Annetha        1       1 Light Jamaican Black Cakewith Strawberr… Red, White …
    ## 2 David          1       1 Chocolate Orange Cake                    Black Fores…
    ## 3 Edd            1       1 Caramel Cinnamon and Banana Cake         <NA>        
    ## 4 Jasminder      1       1 Fresh Mango and Passion Fruit Hummingbi… <NA>        
    ## 5 Jonathan       1       1 Carrot Cake with Lime and Cream Cheese … Three Tiere…
    ## 6 Lea            1       1 Cranberry and Pistachio Cakewith Orange… Raspberries…

``` r
head(result_clean)
```

    ## # A tibble: 6 × 5
    ##   baker     series episode technical result
    ##   <chr>      <dbl>   <dbl>     <dbl> <chr> 
    ## 1 Annetha        1       1         2 IN    
    ## 2 David          1       1         3 IN    
    ## 3 Edd            1       1         1 IN    
    ## 4 Jasminder      1       1        NA IN    
    ## 5 Jonathan       1       1         9 IN    
    ## 6 Louise         1       1        NA IN

check for check for completeness and correctness across datasets

``` r
# Identify bakers without corresponding bakes
bakers_missing_bakes =
  anti_join(baker_clean, bake_clean, by = "baker") %>% 
  anti_join(baker_clean, result_clean, by = "baker")
head(bakers_missing_bakes)
```

    ## # A tibble: 0 × 6
    ## # ℹ 6 variables: baker <chr>, last_name <chr>, series <dbl>, baker_age <dbl>,
    ## #   baker_occupation <chr>, hometown <chr>

there are 0 no-corresponding values

Merge the datasets to create a single final dataset

``` r
baker_bake=
  left_join(baker_clean, bake_clean,by=c("baker","series")) %>% 
  arrange(episode)

result_clean=result_clean %>% arrange(episode)

bake_combine=
  left_join(baker_bake,result_clean,by=c("baker","episode","series")) 
```

exporting datafile bake_combine

``` r
write_csv(bake_combine, "./gbb/bake_combine.csv")
```

My data cleaning process: 1. Step 1: Load and Inspect the Data

2.  Step 2: Handle Missing Values and Inconsistent Data

3.  Step 3: Identify Many-to-Many Relationships:some bakers had multiple
    entries in both the bake_clean and result_clean datasets.

4.  step 4: Split the Baker’s Name into First and Last Name

5.  Step 5: Merge and export the Datasets

Discussion of the final dataset bake_combined: The final dataset is a
merged dataset that contains information about each baker, their bakes,
and their performance results. Key variables include: \*Baker
Information: baker_name, last_name, series, and baker_age.

\*Bake Information: signature_bake, technical_bake, and
showstopper_bake. Performance Results: technical_rank, result (whether
the baker stayed, was eliminated, or became Star Baker).

The dataset is ordered by series and episode, making it easy to track
the performance for each baker across different challenges throughout
the show.

\##create a table shows showing the star baker or winner of each episode
in Seasons 5 through 10
