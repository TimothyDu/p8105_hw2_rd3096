p8105_hw2_rd3096
================

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

# problem1

## load the nyc transit data and clean names

``` r
nyc_subway=
  read_csv("./NYCSUB.csv",na=c("NA","",".")) %>% 
  janitor::clean_names()
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## clean the data as requested

``` r
nyc_subway_clean=nyc_subway %>% 
  select(
    line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(
    entry=
      case_match(
      entry,
      "YES"~TRUE,
      "NO"~ FALSE),
      entry=as.logical(entry)
    )
```

## a short paragraph describing the dataset

The NYC subway dataset contains 1,868 rows and 19 columns. It includes
variables such as line, which represents the subway line (e.g., “4
Avenue”), station_name for the subway station (e.g., “25th St”),
geographical coordinates (station_latitude and station_longitude), and
various subway routes from route1 to route11. Additionally, the dataset
has information on the type of entrance (entrance_type), whether vending
machines are available (vending), and whether the station is ADA
compliant (ada). For the cleaning process, I retained only the necessary
variables and transformed the entry variable, which originally contained
“YES” and “NO” as character values, into a logical format (TRUE/FALSE).
After cleaning, the dataset consists of 1,868 observations and retains
the 19 original columns. While the data is fairly tidy, further steps
may be needed to handle the route variables, which are currently spread
across multiple columns.

## Answer the Questions:

\*How many distinct stations are there? Note that stations are
identified both by name and by line (e.g. 125th St 8th Avenue; 125st
Broadway; 125st Lenox); the distinct function may be useful here.

``` r
distinct_stations=
  nyc_subway_clean %>% 
  distinct(station_name,line) %>% 
  nrow()
```

1.  There are 465 number of distinct stations are stored in
    distinct_stations.

\*How many stations are ADA compliant?

``` r
ada_compliant_stations=
  nyc_subway_clean %>% 
  filter(ada==TRUE) %>% 
  nrow()
```

2.  There are 468 stations are ADA compliant.

\*What proportion of station entrances / exits without vending allow
entrance?

``` r
proportion_no_vending_allows_entry=
  nyc_subway_clean %>%
  filter(vending == "NO") %>%
  summarize(proportion = mean(entry))
```

3.  37.7% of station entrances / exits without vending allow entrance.

## reformat the data to make route number and rount names distinct variables

``` r
nyc_subway_routes_clean= 
  nyc_subway_clean %>%
  mutate(across(route1:route11,as.character)) %>% 
  pivot_longer(
    route1:route11, 
    names_to = "route_number", 
    values_to = "route_name" 
  )
```

## number of distinct stations serve the A train

``` r
a_train_stations=
  nyc_subway_routes_clean %>%
  filter(route_name == "A") %>% 
  distinct(station_name, line) %>% 
  nrow()
```

There are 60 disctinct stations serve the A train.

## number of distinct stations serve the A train that are complaint train

``` r
# Find ADA-compliant stations that serve the A train
ada_compliant_a_train_stations=
  nyc_subway_routes_clean %>%
  filter(route_name == "A", ada == TRUE) %>%
  distinct(station_name, line) %>% 
  nrow()
```

Of the stations that serve the A train, 17 are ADA compliant

# problem 2

``` r
library(readxl)
library(dplyr)
```

## read the Mr. Trash Wheel excel file and clean the data

``` r
mr_trash_wheel=
  read_excel("./TrashWheel.xlsx", sheet="Mr. Trash Wheel", skip=1) %>% janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls=as.integer(round(sports_balls))) %>%
  select(dumpster:homes_powered) %>% 
  mutate(year = as.character(year)) %>% 
mutate(trash_wheel = "Mr. Trash Wheel")
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

## read the Professor Trash Wheel excel file and clean the data

``` r
professor_trash_wheel=
  read_excel("./trashwheel.xlsx", sheet="Professor Trash Wheel", skip=1) %>% janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  select(dumpster:homes_powered) %>% 
  mutate(year = as.character(year)) %>% 
mutate(trash_wheel = "Professor. Trash Wheel")
```

## read the Professor Trash Wheel excel file and clean the data

``` r
gwynnda_trash_wheel=
  read_excel("./trashwheel.xlsx", sheet="Gwynnda Trash Wheel", skip=1) %>% janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  select(dumpster:homes_powered) %>% 
  mutate(year = as.character(year)) %>% 
mutate(trash_wheel = "Gwynnda. Trash Wheel")
```

## combine the datafiles using binding

``` r
combined_trash_wheel=
  bind_rows(
    mr_trash_wheel, 
    professor_trash_wheel, 
    gwynnda_trash_wheel) %>% 
  relocate(trash_wheel)
```

The number of observations in the combined datafile is 1033.Key
variables in the dataset include `dumpster`, which identifies the
dumpster used, `weight_tons` for the weight of trash collected, and
`cigarette_butts` for the number of cigarette butts collected.

``` r
total_weight_professor= combined_trash_wheel %>%
  filter(trash_wheel == "Professor. Trash Wheel") %>%
  summarize(total_weight = sum(weight_tons, na.rm = TRUE)) %>% 
pull(total_weight)


total_cig_butts_gwynnda_june=
  combined_trash_wheel %>%
  filter(trash_wheel == "Gwynnda. Trash Wheel", month == "June", year == "2022") %>%
  summarize(total_cig_butts = sum(cigarette_butts, na.rm = TRUE)) %>% 
  pull(total_cig_butts)
```

The total weight of trash collected by Professor Trash Wheel is 246.74,
the total number of cigarette butts collected by Gwynnda in June of 2022
is 1.812^{4}.

# Problem 3

## import, clean and Tidy three datafiles, bakers, bakes and results.

``` r
baker_clean=
  read_csv("./gbb/bakers.csv",na=c("NA","",".")) %>% 
  janitor::clean_names() %>% 
  separate(baker_name, into=c("baker","last_name"),sep = " ", extra = "merge") %>% 
  relocate(baker) %>% 
  arrange(baker)
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bake_clean=
  read_csv("./gbb/bakes.csv", na=c("N/A","","UNKNOWN","Unknown")) %>%
  janitor::clean_names() %>% 
  relocate(baker)
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
result_clean=
  read_csv("./gbb/results.csv",na=c("NA","","."),skip=2) %>% 
  janitor::clean_names() %>% 
  relocate(baker)
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(baker_clean)
```

    ## # A tibble: 6 × 6
    ##   baker   last_name  series baker_age baker_occupation   hometown               
    ##   <chr>   <chr>       <dbl>     <dbl> <chr>              <chr>                  
    ## 1 Ali     Imdad           4        25 Charity worker     Saltley, Birmingham    
    ## 2 Alice   Fevronia       10        28 Geography teacher  Essex                  
    ## 3 Alvin   Magallanes      6        37 Nurse              Bracknell, Berkshire   
    ## 4 Amelia  LeBruin        10        24 Fashion designer   Halifax                
    ## 5 Andrew  Smyth           7        25 Aerospace engineer Derby / Holywood, Coun…
    ## 6 Annetha Mills           1        30 Midwife            Essex

``` r
head(bake_clean)
```

    ## # A tibble: 6 × 5
    ##   baker     series episode signature_bake                           show_stopper
    ##   <chr>      <dbl>   <dbl> <chr>                                    <chr>       
    ## 1 Annetha        1       1 Light Jamaican Black Cakewith Strawberr… Red, White …
    ## 2 David          1       1 Chocolate Orange Cake                    Black Fores…
    ## 3 Edd            1       1 Caramel Cinnamon and Banana Cake         <NA>        
    ## 4 Jasminder      1       1 Fresh Mango and Passion Fruit Hummingbi… <NA>        
    ## 5 Jonathan       1       1 Carrot Cake with Lime and Cream Cheese … Three Tiere…
    ## 6 Lea            1       1 Cranberry and Pistachio Cakewith Orange… Raspberries…

``` r
head(result_clean)
```

    ## # A tibble: 6 × 5
    ##   baker     series episode technical result
    ##   <chr>      <dbl>   <dbl>     <dbl> <chr> 
    ## 1 Annetha        1       1         2 IN    
    ## 2 David          1       1         3 IN    
    ## 3 Edd            1       1         1 IN    
    ## 4 Jasminder      1       1        NA IN    
    ## 5 Jonathan       1       1         9 IN    
    ## 6 Louise         1       1        NA IN

## check for check for completeness and correctness across datasets

``` r
# Identify bakers without corresponding bakes
bakers_missing_bakes =
  anti_join(baker_clean, bake_clean, by = "baker") %>% 
  anti_join(baker_clean, result_clean, by = "baker")
head(bakers_missing_bakes)
```

    ## # A tibble: 0 × 6
    ## # ℹ 6 variables: baker <chr>, last_name <chr>, series <dbl>, baker_age <dbl>,
    ## #   baker_occupation <chr>, hometown <chr>

there are 0 no-corresponding values

## Merge the datasets to create a single final dataset

``` r
baker_bake=
  left_join(baker_clean, bake_clean,by=c("baker","series")) 

bake_combine=
  left_join(baker_bake,result_clean,by=c("baker","episode","series")) %>% 
  janitor::clean_names() %>% 
  relocate(baker,series,episode)
```

## exporting datafile bake_combine

``` r
write_csv(bake_combine, "./gbb/bake_combine.csv")
```

## My data cleaning process:

1.  Step 1: Load and Inspect the Data

2.  Step 2: Handle Missing Values and Inconsistent Data

3.  step 3: Split the Baker’s Name into First and Last Name

4.  Step 4: Merge and export the Datasets

Discussion of the final dataset bake_combined: The final dataset has 566
rows and 11columns, it contains information about each baker, their
bakes, and their performance results. Key variables include:

\*Baker Information: baker, last_name, series, and baker_age.

\*Bake Information: signature_bake, technical_bake, and
showstopper_bake. Performance Results: technical_rank, result (whether
the baker stayed, was eliminated, or became Star Baker).

The dataset is ordered by series and episode, making it easy to track
the performance for each baker across different challenges throughout
the show.

## create a table shows showing the star baker or winner of each episode in Seasons 5 through 10

``` r
star_win=
  bake_combine %>% 
  filter(series >= 5 & series <= 10,result %in% c("STAR BAKER","WINNER")) %>%
  select(baker,series,episode,result) %>% 
  arrange(series)
star_win
```

    ## # A tibble: 40 × 4
    ##    baker   series episode result    
    ##    <chr>    <dbl>   <dbl> <chr>     
    ##  1 Chetna       5       6 STAR BAKER
    ##  2 Kate         5       5 STAR BAKER
    ##  3 Luis         5       3 STAR BAKER
    ##  4 Nancy        5       1 STAR BAKER
    ##  5 Nancy        5      10 WINNER    
    ##  6 Richard      5       2 STAR BAKER
    ##  7 Richard      5       4 STAR BAKER
    ##  8 Richard      5       7 STAR BAKER
    ##  9 Richard      5       8 STAR BAKER
    ## 10 Richard      5       9 STAR BAKER
    ## # ℹ 30 more rows

In summary, Candice’s dominance in Season 7, with multiple Star Baker
titles and ultimately winning the competition, stands out as
predictable. Ian’s inability to carry his early momentum to an overall
win in Season 6 could be seen as a surprise. Meanwhile, other
contestants, like Andrew and Benjamin, performed well but couldn’t match
Candice’s level of baking.

## import clean and tidy the viewer dataset

``` r
viewer_clean=
  read_csv("./gbb/viewers.csv",na=c("NA","",".")) %>% 
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(viewer_clean,10)
```

    ## # A tibble: 10 × 11
    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ##  1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ##  2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ##  3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ##  4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ##  5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ##  6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ##  7       7    NA        4.42     5.1      7.76    10.3      12.4     13.4
    ##  8       8    NA        5.06     5.35     7.41     9.02     11.1     13.3
    ##  9       9    NA       NA        5.7      7.41    10.7      12.6     13.4
    ## 10      10    NA       NA        6.74     9.45    13.5      15.0     15.9
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

The average viewership in Season 1 is 2.77. The average viewership in
Season 5 is 10.0393.
